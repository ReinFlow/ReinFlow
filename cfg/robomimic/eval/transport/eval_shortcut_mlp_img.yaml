######################################################################
# environment and task
env_name: transport

# future action forecasts
action_dim: 14     # two robots
horizon_steps: 8   # larger for this task.
act_steps: 8

# observation history
obs_dim: 18  # proprioception only, two robots
cond_steps: 1
img_cond_steps: 1

# observation shape
shape_meta:
  obs:
    rgb:
      shape: [6, 96, 96]
    state:
      shape: [18]
  action:
    shape: [14]
###################################################################


defaults:
  - _self_
hydra:
  run:
    dir: ${logdir}
_target_: agent.eval.eval_shortcut_img_agent.EvalImgShortCutAgent

name: ${env_name}_eval_shortcut_mlp_img_ta${horizon_steps}_td${denoising_steps}
logdir: 
  ${oc.env:REINFLOW_LOG_DIR}/robomimic/eval/${name}/${now:%Y-%m-%d}_${now:%H-%M-%S}_${seed}
base_policy_path:
robomimic_env_cfg_path: cfg/robomimic/env_meta/${env_name}-img.json
normalization_path: ${oc.env:REINFLOW_DATA_DIR}/robomimic/${env_name}-img/normalization.npz

load_ema: true
seed: 42
device: cuda:0
denoising_steps: 20 #100
denoising_step_list: [1, 2, 4, 5, 8, 16, 32, 64, 128]
n_steps: 200  # each episode takes max_episode_steps / act_steps steps
render_num: 0
batch_size: 128

env:
  n_envs: 50
  name: ${env_name}
  best_reward_threshold_for_success: 1
  max_episode_steps: 800
  save_video: false
  use_image_obs: true
  wrappers:
    robomimic_image:
      normalization_path: ${normalization_path}
      low_dim_keys: ['robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', "robot1_eef_pos",
        "robot1_eef_quat", "robot1_gripper_qpos"]
      image_keys: ['shouldercamera0_image', 'shouldercamera1_image']
      shape_meta: ${shape_meta}
    multi_step:
      n_obs_steps: ${cond_steps}
      n_action_steps: ${act_steps}
      max_episode_steps: ${env.max_episode_steps}
      reset_within_step: true
  render: true

model:
  _target_: model.flow.shortcutflow.ShortCutFlow
  network:
    _target_: model.flow.mlp_shortcut.ShortCutFlowViT
    backbone:
      _target_: model.common.vit.VitEncoder
      obs_shape: ${shape_meta.obs.rgb.shape}
      num_channel: ${eval:'3 * ${img_cond_steps}'} # each image patch is history concatenated
      cfg:
        patch_size: 8
        depth: 1
        embed_dim: 128
        num_heads: 4
        embed_style: embed2
        embed_norm: 0
    action_dim: ${action_dim}
    horizon_steps: ${horizon_steps}
    prop_dim: ${eval:'${obs_dim} * ${cond_steps}'}
    img_cond_steps: ${img_cond_steps}
    td_emb_dim: 32
    mlp_dims: [768, 768, 768]
    cond_mlp_dims: [96, 48, 32] # to accomodate twice the complexity brought by two arms, while not being too complex as the dataset still only contains 100 episodes. 
    residual_style: true
    num_img: 2
    augment: true
    spatial_emb: 128
    embed_combination_type: 'add'
  device: ${device}
  horizon_steps: ${horizon_steps}
  action_dim: ${action_dim}
  act_min: -1
  act_max: 1
  obs_dim: ${obs_dim}
  max_denoising_steps: ${denoising_steps}
  seed: ${seed}
  self_consistency_k: 0.25
  delta: 1e-5
  sample_t_type: uniform # beta, logitnormal
