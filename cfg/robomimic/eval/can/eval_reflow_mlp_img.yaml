defaults:
  - _self_
hydra:
  run:
    dir: ${logdir}
_target_: agent.eval.eval_reflow_img_agent.EvalImgReFlowAgent

name: ${env_name}_eval_reflow_mlp_img_ta${horizon_steps}_td${denoising_steps}
logdir: 
  ${oc.env:REINFLOW_LOG_DIR}/robomimic/eval/${name}/${now:%Y-%m-%d}_${now:%H-%M-%S}_${seed}
base_policy_path: ${oc.env:REINFLOW_LOG_DIR}/robomimic/pretrain/can/ReFlow/state_2000.pt
robomimic_env_cfg_path: cfg/robomimic/env_meta/${env_name}-img.json
normalization_path: ${oc.env:REINFLOW_DATA_DIR}/robomimic/${env_name}-img/normalization.npz

load_ema: true
seed: 42
device: cuda:0
env_name: can
obs_dim: 9
action_dim: 7
denoising_steps: 100
cond_steps: 1
img_cond_steps: 1
horizon_steps: 4
act_steps: 4
denoising_step_list: [1, 2, 4, 5, 8, 16, 32, 64, 128]

n_steps: 300  # each episode takes max_episode_steps / act_steps steps
render_num: 0
batch_size: 128

env:
  n_envs: 50
  name: ${env_name}
  best_reward_threshold_for_success: 1
  max_episode_steps: 300
  save_video: false
  use_image_obs: true
  wrappers:
    robomimic_image:
      normalization_path: ${normalization_path}
      low_dim_keys: ['robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos']
      image_keys: ['robot0_eye_in_hand_image']
      shape_meta: ${shape_meta}
    multi_step:
      n_obs_steps: ${cond_steps}
      n_action_steps: ${act_steps}
      max_episode_steps: ${env.max_episode_steps}
      reset_within_step: true
  render: true

shape_meta:
  obs:
    rgb:
      shape: [3, 96, 96]
    state:
      shape: [9]
  action:
    shape: [7]

model:
  _target_: model.flow.reflow.ReFlow
  network:
    _target_: model.flow.mlp_flow.VisionFlowMLP
    backbone:
      _target_: model.common.vit.VitEncoder
      obs_shape: ${shape_meta.obs.rgb.shape}
      num_channel: ${eval:'${shape_meta.obs.rgb.shape[0]} * ${img_cond_steps}'} # each image patch is history concatenated
      cfg:
        patch_size: 8
        depth: 1
        embed_dim: 128
        num_heads: 4
        embed_style: embed2
        embed_norm: 0
    img_cond_steps: ${img_cond_steps}
    augment: true
    spatial_emb: 128
    time_dim: 32
    mlp_dims: [512, 512, 512]
    residual_style: true
    cond_dim: ${eval:'${obs_dim} * ${cond_steps}'}
    horizon_steps: ${horizon_steps}
    action_dim: ${action_dim}
  device: ${device}
  horizon_steps: ${horizon_steps}
  action_dim: ${action_dim}
  act_min: -1
  act_max: 1
  obs_dim: ${obs_dim}
  max_denoising_steps: ${denoising_steps}
  seed: ${seed}
  sample_t_type: uniform # beta, logitnormal
